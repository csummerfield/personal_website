<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Christopher Summerfield — Professor of Cognitive Neuroscience at the University of Oxford, Research Director at the UK AI Security Institute, and author.">
    <meta property="og:title" content="Christopher Summerfield | Books & AI Research">
    <meta property="og:description" content="Professor of Cognitive Neuroscience at the University of Oxford, Research Director at the UK AI Security Institute, and author of Natural General Intelligence and These Strange New Minds.">
    <meta property="og:type" content="website">
    <title>Christopher Summerfield | Books & AI Research</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <header class="site-header">
        <h1>Christopher Summerfield</h1>
        <p class="subtitle">Cognitive Scientist &middot; Neuroscientist &middot; AI Researcher &middot; Author</p>
    </header>

    <nav class="site-nav">
        <a href="#about">About</a>
        <a href="#books">Books</a>
        <a href="#ai-research">AI Research</a>
    </nav>

    <main class="container">

        <section id="about" class="section">
            <h2>About</h2>
            <div class="about-content">
                <img src="cyclologist.jpg" alt="Christopher Summerfield" class="profile-image" width="240" height="320">
                <div class="about-text">
                    <p>I am Professor of Cognitive Neuroscience at the University of Oxford, and a Research Director at the <a href="https://www.aisi.gov.uk/" target="_blank" rel="noopener">UK AI Security Institute</a>. My work focuses on understanding the <a href="https://humaninformationprocessing.com/publications/" target="_blank" rel="noopener">cognitive and neural mechanisms</a> that underlie human learning and decision-making, and on studying the <a href="https://humaninformationprocessing.com/publications_AI/" target="_blank" rel="noopener">impacts of AI on society</a>.</p>

                    <p>My research bridges the fields of cognitive science, neuroscience, and artificial intelligence. I am particularly interested in how insights from human cognition can inform the development of more advanced and safer AI systems.</p>

                    <p>I lead the Human Information Processing (HIP) lab in the Department of Experimental Psychology at the University of Oxford. For more information about my academic work and lab, please visit <a href="https://www.humaninformationprocessing.com" target="_blank" rel="noopener">humaninformationprocessing.com</a> or view my <a href="https://scholar.google.com/citations?user=ymlcN9AAAAAJ&hl=en" target="_blank" rel="noopener">Google Scholar profile</a>.</p>
                </div>
            </div>
        </section>

        <section id="books" class="section">
            <h2>Books</h2>

            <div class="book">
                <img src="natural_general_intelligence_cover.jpeg" alt="Natural General Intelligence Cover" class="book-cover">
                <div class="book-content">
                    <h3>Natural General Intelligence</h3>
                    <h4>How understanding the brain can help us build AI</h4>
                    <p class="publisher">Oxford University Press, 2022</p>
                    <p>Explores the algorithms and architectures that are driving progress in AI research. This book discusses intelligence in the language of psychology and biology, using examples and analogies to be comprehensible to a wide audience. It tackles longstanding theoretical questions about the nature of thought and knowledge.</p>
                    <p><a href="https://global.oup.com/academic/product/natural-general-intelligence-9780192843883" target="_blank" rel="noopener">Learn More</a></p>
                </div>
            </div>

            <div class="book">
                <img src="these_strange_new_minds_cover.jpeg" alt="These Strange New Minds Cover" class="book-cover">
                <div class="book-content">
                    <h3>These Strange New Minds</h3>
                    <h4>How AI Learned to Talk and What It Means</h4>
                    <p class="publisher">Penguin Random House, 2025</p>
                    <p>An insider look at the Large Language Models (LLMs) that are revolutionizing our relationship to technology, exploring their surprising history, what they can and should do for us today, and where they will go in the future. This accessible, up-to-date, and authoritative examination of the world's most radical technology explores what it really takes to build a brain from scratch.</p>
                    <p><a href="https://www.penguinrandomhouse.com/books/750406/these-strange-new-minds-by-christopher-summerfield/" target="_blank" rel="noopener">Learn More</a></p>
                    <div class="testimonials">
                        <blockquote class="testimonial">
                            <p>"An engaging, insightful and panoramic survey of where we are, why we got here and what it means. A brilliant guide to the most important technology of our times."</p>
                            <cite>— Mustafa Suleyman, CEO of Microsoft AI &amp; Cofounder of DeepMind</cite>
                        </blockquote>
                        <blockquote class="testimonial">
                            <p>"By far the best guide to a newly emerging species with which we will share the planet for the foreseeable future."</p>
                            <cite>— Stuart Russell, author of Human Compatible</cite>
                        </blockquote>
                    </div>
                </div>
            </div>
        </section>

        <section id="ai-research" class="section">
            <h2>AI Research</h2>

            <div class="research-section">
                <h3>DeepMind UK</h3>
                <p>I am a former Research Scientist at DeepMind UK (2010–2023). My work at DeepMind focussed on using AI to help design beneficial social, economic and political mechanisms. Example projects used reinforcement learning (RL) to design fair and sustainable redistribution principles (<a href="https://www.nature.com/articles/s41562-022-01383-x" target="_blank" rel="noopener">Koster et al 2022</a>, <a href="https://www.nature.com/articles/s41467-025-58043-7" target="_blank" rel="noopener">Koster et al 2024</a>) and using LLMs to help people find agreement (<a href="https://www.science.org/doi/10.1126/science.adq2852" target="_blank" rel="noopener">Tessler et al 2024</a>).</p>
            </div>

            <div class="research-section">
                <h3>UK AI Security Institute</h3>
                <p>As a Research Director at the UK AI Security Institute, I lead work on societal impacts of artificial intelligence. My research studies how AI systems might create harm by being used to manipulate or influence people, or by creating new opportunities for criminal or socially destabilising activities. Much of our work monitors how AI is being deployed in the real world, and explores solutions that may help guard against the risks it incurs.</p>
            </div>
        </section>

    </main>

    <footer class="site-footer">
        <p><a href="mailto:christopher.summerfield@psy.ox.ac.uk">christopher.summerfield@psy.ox.ac.uk</a></p>
    </footer>

</body>
</html>
